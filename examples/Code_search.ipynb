{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コード検索\n",
    "\n",
    "このノートブックでは、Ada埋め込み（embeddings）を使ってセマンティックコード検索を実装する方法を示します。このデモンストレーションでは、独自の[openai-python コードリポジトリ](https://github.com/openai/openai-python)を使用しています。Pythonファイルから関数を抽出して埋め込み、インデックス化、クエリする簡易版のファイルパーシングを実装します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ヘルパー関数\n",
    "\n",
    "まず、コードベースから重要な情報を抽出するための簡単なパーシング関数をセットアップします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Generator\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "DEF_PREFIXES = ['def ', 'async def ']\n",
    "NEWLINE = '\\n'\n",
    "\n",
    "def extract_function_name(code: str) -> str:\n",
    "    \"\"\"\n",
    "    'def'または'async def'で始まる行から関数名を抽出します。\n",
    "\n",
    "    Args:\n",
    "    - code (str): コード行\n",
    "\n",
    "    Returns:\n",
    "    - str: 関数名\n",
    "    \"\"\"\n",
    "    for prefix in DEF_PREFIXES:\n",
    "        if code.startswith(prefix):\n",
    "            return code[len(prefix): code.index('(')]\n",
    "\n",
    "def collect_until_out_of_scope(all_lines: List[str], start_idx: int) -> str:\n",
    "    \"\"\"\n",
    "    関数定義が終わるまでのすべての行を収集します。\n",
    "\n",
    "    Args:\n",
    "    - all_lines (List[str]): 全コード行のリスト\n",
    "    - start_idx (int): 関数定義の開始行のインデックス\n",
    "\n",
    "    Returns:\n",
    "    - str: 関数定義のコード\n",
    "    \"\"\"\n",
    "    ret = [all_lines[start_idx]]\n",
    "    for i in range(start_idx + 1, len(all_lines)):\n",
    "        if all_lines[i].strip():\n",
    "            ret.append(all_lines[i])\n",
    "        else:\n",
    "            break\n",
    "    return NEWLINE.join(ret)\n",
    "\n",
    "def parse_functions_in_file(filepath: str) -> Generator[Dict[str, str], None, None]:\n",
    "    \"\"\"\n",
    "    Pythonファイル内のすべての関数を抽出します。\n",
    "\n",
    "    Args:\n",
    "    - filepath (str): Pythonファイルのパス\n",
    "\n",
    "    Yields:\n",
    "    - Dict[str, str]: 関数情報（コード、関数名、ファイルパス）\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        all_lines = file.read().replace('\\r', NEWLINE).split(NEWLINE)\n",
    "        for idx, line in enumerate(all_lines):\n",
    "            for prefix in DEF_PREFIXES:\n",
    "                if line.startswith(prefix):\n",
    "                    code = collect_until_out_of_scope(all_lines, idx)\n",
    "                    function_name = extract_function_name(code)\n",
    "                    yield {\n",
    "                        'code': code,\n",
    "                        'function_name': function_name,\n",
    "                        'filepath': filepath,\n",
    "                    }\n",
    "                    break\n",
    "\n",
    "def extract_all_functions_from_repo(code_root: Path) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    リポジトリ内のすべての.py関数を抽出します。\n",
    "\n",
    "    Args:\n",
    "    - code_root (Path): コードのルートディレクトリのPathオブジェクト\n",
    "\n",
    "    Returns:\n",
    "    - List[Dict[str, str]]: すべての関数の情報\n",
    "    \"\"\"\n",
    "    code_files = list(code_root.glob('**/*.py'))\n",
    "\n",
    "    num_files = len(code_files)\n",
    "    print(f'.pyファイルの総数: {num_files}')\n",
    "\n",
    "    if num_files == 0:\n",
    "        print('リポジトリが存在しないか、code_rootが正しく設定されていません。')\n",
    "        return []\n",
    "\n",
    "    all_functions = [\n",
    "        func\n",
    "        for code_file in code_files\n",
    "        for func in parse_functions_in_file(str(code_file))\n",
    "    ]\n",
    "\n",
    "    num_functions = len(all_functions)\n",
    "    print(f'抽出された関数の総数: {num_functions}')\n",
    "\n",
    "    return all_functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データのロード\n",
    "\n",
    "まず、`openai-python` フォルダを読み込み、上で定義した関数を用いて必要な情報を抽出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ユーザーのルートディレクトリ: /root\n",
      ".pyファイルの総数: 17\n",
      "抽出された関数の総数: 45\n"
     ]
    }
   ],
   "source": [
    "# Set user root directory to the 'openai-python' repository\n",
    "root_dir = Path.home()\n",
    "print(f'ユーザーのルートディレクトリ: {root_dir}')\n",
    "# Assumes the 'openai-python' repository exists in the user's root directory\n",
    "code_root = root_dir / 'openai-python'\n",
    "\n",
    "# Extract all functions from the repository\n",
    "all_funcs = extract_all_functions_from_repo(code_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コンテンツが用意できたので、このデータをテキスト埋め込み用の「text-embedding-ada-002」エンドポイントに渡して、ベクトル埋め込みを取得することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>function_name</th>\n",
       "      <th>filepath</th>\n",
       "      <th>code_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>def get_hyperlinks(url):\\n    # Try to open th...</td>\n",
       "      <td>get_hyperlinks</td>\n",
       "      <td>web-crawl-q-and-a/web-qa.py</td>\n",
       "      <td>[-0.0062524136155843735, 0.012277018278837204,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>def get_domain_hyperlinks(local_domain, url):\\...</td>\n",
       "      <td>get_domain_hyperlinks</td>\n",
       "      <td>web-crawl-q-and-a/web-qa.py</td>\n",
       "      <td>[-0.008532723411917686, 0.019567523151636124, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>def crawl(url):\\n    # Parse the URL and get t...</td>\n",
       "      <td>crawl</td>\n",
       "      <td>web-crawl-q-and-a/web-qa.py</td>\n",
       "      <td>[0.02908903919160366, 0.019636360928416252, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>def remove_newlines(serie):\\n    serie = serie...</td>\n",
       "      <td>remove_newlines</td>\n",
       "      <td>web-crawl-q-and-a/web-qa.py</td>\n",
       "      <td>[-0.00836277287453413, -0.0018864485900849104,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>def split_into_many(text, max_tokens=max_token...</td>\n",
       "      <td>split_into_many</td>\n",
       "      <td>web-crawl-q-and-a/web-qa.py</td>\n",
       "      <td>[-0.006750369910150766, 0.016972357407212257, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                code          function_name  \\\n",
       "0  def get_hyperlinks(url):\\n    # Try to open th...         get_hyperlinks   \n",
       "1  def get_domain_hyperlinks(local_domain, url):\\...  get_domain_hyperlinks   \n",
       "2  def crawl(url):\\n    # Parse the URL and get t...                  crawl   \n",
       "3  def remove_newlines(serie):\\n    serie = serie...        remove_newlines   \n",
       "4  def split_into_many(text, max_tokens=max_token...        split_into_many   \n",
       "\n",
       "                      filepath  \\\n",
       "0  web-crawl-q-and-a/web-qa.py   \n",
       "1  web-crawl-q-and-a/web-qa.py   \n",
       "2  web-crawl-q-and-a/web-qa.py   \n",
       "3  web-crawl-q-and-a/web-qa.py   \n",
       "4  web-crawl-q-and-a/web-qa.py   \n",
       "\n",
       "                                      code_embedding  \n",
       "0  [-0.0062524136155843735, 0.012277018278837204,...  \n",
       "1  [-0.008532723411917686, 0.019567523151636124, ...  \n",
       "2  [0.02908903919160366, 0.019636360928416252, 0....  \n",
       "3  [-0.00836277287453413, -0.0018864485900849104,...  \n",
       "4  [-0.006750369910150766, 0.016972357407212257, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai.embeddings_utils import get_embedding\n",
    "\n",
    "df = pd.DataFrame(all_funcs)\n",
    "df['code_embedding'] = df['code'].apply(lambda x: get_embedding(x, engine='text-embedding-ada-002'))\n",
    "df['filepath'] = df['filepath'].map(lambda x: Path(x).relative_to(code_root))\n",
    "df.to_csv(\"data/code_search_openai-python.csv\", index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テスト\n",
    "\n",
    "エンドポイントをいくつかのシンプルなクエリでテストしてみましょう。もし`openai-python`リポジトリに慣れているなら、簡単な英語の説明だけで求める関数を簡単に見つけられることに気付くでしょう。\n",
    "\n",
    "`search_functions`というメソッドを定義し、データベースに含まれるエンベディング、クエリ文字列、そしてその他の設定オプションを引数として取ります。データベースを検索するプロセスは以下のように動作します：\n",
    "\n",
    "1. 最初にクエリ文字列（`code_query`）を`text-embedding-ada-002`でエンベディングします。ここでの理由は、'a function that reverses a string' というようなクエリ文字列と、'def reverse(string): return string[::-1]' のような関数が、エンベディングされたときに非常に類似しているでしょう。\n",
    "2. 次に、クエリ文字列のエンベディングとデータベース内の全データポイントとのコサイン類似度を計算します。これによって各ポイントとクエリとの間の距離が得られます。\n",
    "3. 最後に、クエリ文字列との距離に基づいて全データポイントをソートし、関数パラメータで要求された数の結果を返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import cosine_similarity\n",
    "\n",
    "def search_functions(df, code_query, n=3, pprint=True, n_lines=7):\n",
    "    embedding = get_embedding(code_query, engine='text-embedding-ada-002')\n",
    "    df['similarities'] = df.code_embedding.apply(lambda x: cosine_similarity(x, embedding))\n",
    "\n",
    "    res = df.sort_values('similarities', ascending=False).head(n)\n",
    "\n",
    "    if pprint:\n",
    "        for r in res.iterrows():\n",
    "            print(f\"{r[1].filepath}:{r[1].function_name}  score={round(r[1].similarities, 3)}\")\n",
    "            print(\"\\n\".join(r[1].code.split(\"\\n\")[:n_lines]))\n",
    "            print('-' * 70)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatbot-kickstarter/database.py:load_vectors  score=0.709\n",
      "def load_vectors(client:Redis, input_list, vector_field_name):\n",
      "    p = client.pipeline(transaction=False)\n",
      "    for text in input_list:    \n",
      "        #hash key\n",
      "        key=f\"{PREFIX}:{text['id']}\"\n",
      "----------------------------------------------------------------------\n",
      "chatbot-kickstarter/database.py:create_hnsw_index   score=0.688\n",
      "def create_hnsw_index (redis_conn,vector_field_name,vector_dimensions=1536, distance_metric='COSINE'):\n",
      "    redis_conn.ft().create_index([\n",
      "        VectorField(vector_field_name, \"HNSW\", {\"TYPE\": \"FLOAT32\", \"DIM\": vector_dimensions, \"DISTANCE_METRIC\": distance_metric}),\n",
      "        TextField(\"filename\"),\n",
      "        TextField(\"text_chunk\"),        \n",
      "        NumericField(\"file_chunk_index\")\n",
      "    ])\n",
      "----------------------------------------------------------------------\n",
      "embeddings-playground/embeddings_playground.py:embedding_from_string  score=0.682\n",
      "def embedding_from_string(input: str, model: str) -> list:\n",
      "    response = openai.Embedding.create(input=input, model=model)\n",
      "    embedding = response[\"data\"][0][\"embedding\"]\n",
      "    return embedding\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "res = search_functions(df, 'fine-tuning input data validation logic', n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatbot-kickstarter/transformers.py:get_unique_id_for_file_chunk  score=0.714\n",
      "def get_unique_id_for_file_chunk(filename, chunk_index):\n",
      "    return str(filename+\"-!\"+str(chunk_index))\n",
      "----------------------------------------------------------------------\n",
      "file-q-and-a/nextjs-with-flask-server/server/utils.py:get_pinecone_id_for_file_chunk  score=0.709\n",
      "def get_pinecone_id_for_file_chunk(session_id, filename, chunk_index):\n",
      "    return str(session_id+\"-!\"+filename+\"-!\"+str(chunk_index))\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "res = search_functions(df, 'find common suffix', n=2, n_lines=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enterprise-knowledge-retrieval/assistant.py:initiate_agent  score=0.711\n",
      "def initiate_agent(tools):\n",
      "    prompt = CustomPromptTemplate(\n",
      "        template=SYSTEM_PROMPT,\n",
      "        tools=tools,\n",
      "        # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
      "        # The history template includes \"history\" as an input variable so we can interpolate it into the prompt\n",
      "        input_variables=[\"input\", \"intermediate_steps\", \"history\"],\n",
      "    )\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "res = search_functions(df, 'Command line interface for fine-tuning', n=1, n_lines=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
