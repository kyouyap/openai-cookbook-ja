{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a06ec76c",
   "metadata": {},
   "source": [
    "# チャットモデルのファインチューニング用のデータ準備と分析\n",
    "\n",
    "このノートブックは、チャットモデルのファインチューニングに使用されるチャットデータセットを前処理および分析するためのツールとして機能します。\n",
    "フォーマットエラーのチェック、基本統計の提供、およびファインチューニング費用のトークン数の推定を行います。\n",
    "ここで示される方法は、babbage-002 や davinci-002 などのモデルに対する[レガシーファインチューニング](https://platform.openai.com/docs/guides/legacy-fine-tuning)に対応しています。\n",
    "GPT-3.5-turboのファインチューニングについては、[現行のファインチューニングページ](https://platform.openai.com/docs/guides/fine-tuning)を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e63973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tiktoken # for token counting\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "013bdbc4",
   "metadata": {},
   "source": [
    "## データの読み込み\n",
    "\n",
    "最初に、チャットのデータセットを[サンプルのJSONLファイル](https://github.com/openai/openai-cookbook/blob/main/examples/data/toy_chat_fine_tuning.jsonl)から読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c248ccd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 5\n",
      "First example:\n",
      "{'role': 'system', 'content': 'You are a happy assistant that puts a positive spin on everything.'}\n",
      "{'role': 'user', 'content': 'I fell off my bike today.'}\n",
      "{'role': 'assistant', 'content': \"It's great that you're getting exercise outdoors!\"}\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data/toy_chat_fine_tuning.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17903d61",
   "metadata": {},
   "source": [
    "## フォーマットの検証\n",
    "\n",
    "データセット内の各会話がファインチューニングAPIが期待するフォーマットに従っているかを確認するために、さまざまなエラーチェックを実行できます。エラーは、デバッグが簡単に行えるように、その性質に基づいてカテゴリー分けされています。\n",
    "\n",
    "1. **データタイプチェック**: データセット内の各エントリが辞書（`dict`）であるかどうかをチェックします。エラータイプ：`data_type`。\n",
    "2. **メッセージリストの存在確認**: 各エントリに`messages`リストが存在するかどうかをチェックします。エラータイプ：`missing_messages_list`。\n",
    "3. **メッセージキーチェック**: `messages`リスト内の各メッセージに`role`と`content`のキーが含まれているかどうかを確認します。エラータイプ：`message_missing_key`。\n",
    "4. **メッセージ内の未認識キー**: メッセージに`role`、`content`、および`name`以外のキーがある場合にログを出力します。エラータイプ：`message_unrecognized_key`。\n",
    "5. **ロールの検証**: `role`が\"system\"、\"user\"、または\"assistant\"のいずれであるかを確認します。エラータイプ：`unrecognized_role`。\n",
    "6. **コンテンツの検証**: `content`にテキストデータがあり、文字列であることを確認します。エラータイプ：`missing_content`。\n",
    "7. **アシスタントメッセージの存在確認**: 各会話に少なくとも1つのアシスタントからのメッセージがあるかどうかを確認します。エラータイプ：`example_missing_assistant_message`。\n",
    "\n",
    "以下のコードはこれらのチェックを実行し、見つかった各タイプのエラーの数を出力します。これはデバッグや、データセットが次のステップに進む準備ができているかを確認するのに役立ちます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9f3ccbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        if not content or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "981e77da",
   "metadata": {},
   "source": [
    "## トークン数カウントユーティリティ\n",
    "\n",
    "このノートブックの残りの部分で使用するために、いくつかの便利なユーティリティを定義しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f4b47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fdff67d",
   "metadata": {},
   "source": [
    "## データの警告とトークン数\n",
    "\n",
    "軽量な分析を行うことで、データセットにおける潜在的な問題、例えばメッセージの欠落やメッセージとトークンの数に関する統計的な洞察を提供できます。\n",
    "\n",
    "1. **システム/ユーザーメッセージの不足**: \"system\" または \"user\" メッセージが欠落している対話の数をカウントします。このようなメッセージは、アシスタントの振る舞いを定義し、対話を開始するために重要です。\n",
    "2. **各例のメッセージ数**: 各対話内のメッセージ数の分布を要約し、対話の複雑さに関する洞察を提供します。\n",
    "3. **各例の合計トークン数**: 各対話内のトークンの総数を計算し、その分布を要約します。ファインチューニングのコストを理解するために重要です。\n",
    "4. **アシスタントのメッセージ内のトークン数**: 各対話ごとにアシスタントのメッセージ内のトークン数を計算し、この分布を要約します。アシスタントの冗長性を理解するのに役立ちます。\n",
    "5. **トークン制限の警告**: 例が最大トークン制限（4096トークン）を超過しているかどうかをチェックします。このような例はファインチューニング中に切り詰められる可能性があり、データの損失を引き起こす可能性があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52e58ee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "システムメッセージが欠けている例の数: 1\n",
      "ユーザーメッセージが欠けている例の数: 1\n",
      "\n",
      "#### Distribution of 例ごとのメッセージ数:\n",
      "min / max: 2, 9\n",
      "mean / median: 3.8, 3.0\n",
      "p5 / p95: 2.0, 6.6000000000000005\n",
      "\n",
      "#### Distribution of 例ごとの合計トークン数:\n",
      "min / max: 26, 8032\n",
      "mean / median: 1648.4, 45.0\n",
      "p5 / p95: 26.8, 4863.6\n",
      "\n",
      "#### Distribution of 例ごとのアシスタントメッセージのトークン数:\n",
      "min / max: 4, 8000\n",
      "mean / median: 1610.2, 10.0\n",
      "p5 / p95: 6.0, 4811.200000000001\n",
      "\n",
      "4096トークン制限を超える可能性がある例の数: 1 これらはファインチューニング中に切り詰められます\n"
     ]
    }
   ],
   "source": [
    "# 警告とトークンの数をカウントします\n",
    "n_missing_system = 0  # システムメッセージが欠けている例の数\n",
    "n_missing_user = 0  # ユーザーメッセージが欠けている例の数\n",
    "n_messages = []  # 各例のメッセージ数のリスト\n",
    "convo_lens = []  # 各例の合計トークン数のリスト\n",
    "assistant_message_lens = []  # 各例のアシスタントメッセージのトークン数のリスト\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "print(\"システムメッセージが欠けている例の数:\", n_missing_system)\n",
    "print(\"ユーザーメッセージが欠けている例の数:\", n_missing_user)\n",
    "print_distribution(n_messages, \"例ごとのメッセージ数\")\n",
    "print_distribution(convo_lens, \"例ごとの合計トークン数\")\n",
    "print_distribution(assistant_message_lens, \"例ごとのアシスタントメッセージのトークン数\")\n",
    "n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "print(f\"\\n{4096}トークン制限を超える可能性がある例の数: {n_too_long} これらはファインチューニング中に切り詰められます\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2afb04df",
   "metadata": {},
   "source": [
    "## コストの見積もり\n",
    "\n",
    "この最終セクションでは、ファインチューニングに使用されるトークンの総数を見積もり、それに基づいてコストを近似します。なお、ファインチューニングジョブの所要時間もトークン数とともに増加することに注意する価値があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb95a7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データセットにはトレーニング中に課金されるトークンが約4306個含まれています\n",
      "デフォルトでは、このデータセットで20エポックのトレーニングが行われます\n",
      "デフォルトでは、約86120個のトークンに対して課金されます\n"
     ]
    }
   ],
   "source": [
    "# 価格設定とデフォルトのエポック数の見積もり\n",
    "MAX_TOKENS_PER_EXAMPLE = 4096  # 1つの例あたりの最大トークン数\n",
    "\n",
    "TARGET_EPOCHS = 3  # ターゲットのエポック数\n",
    "MIN_TARGET_EXAMPLES = 100  # 最小のターゲット例数\n",
    "MAX_TARGET_EXAMPLES = 25000  # 最大のターゲット例数\n",
    "MIN_DEFAULT_EPOCHS = 1  # 最小のデフォルトエポック数\n",
    "MAX_DEFAULT_EPOCHS = 25  # 最大のデフォルトエポック数\n",
    "\n",
    "n_epochs = TARGET_EPOCHS  # エポック数の初期値\n",
    "n_train_examples = len(dataset)  # データセットの訓練例数\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "# トレーニング中に課金されるトークン数を計算\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"データセットにはトレーニング中に課金されるトークンが約{n_billing_tokens_in_dataset}個含まれています\")\n",
    "print(f\"デフォルトでは、このデータセットで{n_epochs}エポックのトレーニングが行われます\")\n",
    "print(f\"デフォルトでは、約{n_epochs * n_billing_tokens_in_dataset}個のトークンに対して課金されます\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0ad0369",
   "metadata": {},
   "source": [
    "See https://openai.com/pricing to estimate total costs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
